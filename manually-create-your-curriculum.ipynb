{"cells":[{"cell_type":"markdown","metadata":{"id":"zizCmXtK5BCg"},"source":["# Set up your instance - gpu and google drive"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3612,"status":"ok","timestamp":1698188723746,"user":{"displayName":"Kyoung Choe","userId":"14938553623215115470"},"user_tz":420},"id":"Hgfzhh5i4IxT"},"outputs":[],"source":["# Check if (NVIDIA) GPU is available\n","import torch\n","assert torch.cuda.is_available, \"CUDA gpu not available\""]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1698188724904,"user":{"displayName":"Kyoung Choe","userId":"14938553623215115470"},"user_tz":420},"id":"TDwjqsdt5niQ"},"outputs":[],"source":["# Set up the work directory\n","import os\n","assert os.path.exists(\"/content/drive/MyDrive\"), \"Google Drive not mounted\"\n","\n","WORK_DIR = \"/content/drive/MyDrive/nmmo/\"\n","CKPT_DIR = WORK_DIR + \"runs\""]},{"cell_type":"markdown","metadata":{"id":"dEJ_gJO554d3"},"source":["# Install nmmo env, pufferlib, and the baselines\n","\n","See https://www.aicrowd.com/showcase/colab-starter-kit, if you are new to this.\n","\n","When you restart your colab, you have to pip install nmmo, pufferlib, and baselines deps.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22600,"status":"ok","timestamp":1698192168141,"user":{"displayName":"Kyoung Choe","userId":"14938553623215115470"},"user_tz":420},"id":"rZoaBrDs5qA-","outputId":"04d1ed3f-0995-4138-a09c-6c816db019c3"},"outputs":[],"source":["# # This code assumes you've already downloaded the baselines repo in your google drive\n","# # If not, please go through this first https://www.aicrowd.com/showcase/colab-starter-kit\n","# assert os.path.exists(WORK_DIR), \"Work directory not found. First, follow https://www.aicrowd.com/showcase/colab-starter-kit\"\n","\n","# %cd $WORK_DIR\n","# %cd baselines\n","\n","# # Install nmmo env and pufferlib\n","# !pip install nmmo pufferlib > /dev/null\n","# !pip install -r requirements_colab.txt > /dev/null\n","\n","# !pip show nmmo  # should be 2.0.3\n","# !pip show pufferlib # should be 0.4.3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":106710,"status":"ok","timestamp":1698173074311,"user":{"displayName":"Kyoung Choe","userId":"14938553623215115470"},"user_tz":420},"id":"9SujeV7Z6U0_","outputId":"45660947-ad5f-46fa-e0e2-c638beb35608"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO:root:Training run: nmmo_20231024_184251 (/content/drive/MyDrive/nmmo/runs/nmmo_20231024_184251)\n","INFO:root:Training args: Namespace(attend_task='none', attentional_decode=True, bptt_horizon=8, checkpoint_interval=30, clip_coef=0.1, death_fog_tick=None, device='cuda', early_stop_agent_num=8, encode_task=True, eval_batch_size=32768, eval_mode=False, eval_num_policies=2, eval_num_rounds=1, eval_num_steps=1000000, explore_bonus_weight=0.01, extra_encoders=True, heal_bonus_weight=0.03, hidden_size=256, input_size=256, learner_weight=1.0, local_mode=True, map_size=128, maps_path='maps/train/', max_episode_length=1024, max_opponent_policies=0, meander_bonus_weight=0.02, num_agents=128, num_buffers=1, num_cores=None, num_envs=1, num_lstm_layers=0, num_maps=128, num_npcs=256, policy_store_dir=None, ppo_learning_rate=0.00015, ppo_training_batch_size=128, ppo_update_epochs=3, resilient_population=0.2, rollout_batch_size=1024, run_name='nmmo_20231024_184251', runs_dir='/content/drive/MyDrive/nmmo/runs', seed=1, spawn_immunity=20, sqrt_achievement_rewards=False, task_size=4096, tasks_path='reinforcement_learning/curriculum_with_embedding.pkl', track='rl', train_num_steps=5000, use_serial_vecenv=True, wandb_entity=None, wandb_project=None)\n","INFO:root:Using policy store from /content/drive/MyDrive/nmmo/runs/nmmo_20231024_184251/policy_store\n","INFO:root:Generating 128 maps\n","Allocated 94.38 MB to environments. Only accurate for Serial backend.\n","PolicyPool sample_weights: [128]\n","Allocated to storage - Pytorch: 0.00 GB, System: 0.11 GB\n","INFO:root:PolicyPool: Updated policies: dict_keys(['learner'])\n","Allocated during evaluation - Pytorch: 0.01 GB, System: 1.53 GB\n","Epoch: 0 - 1K steps - 0:01:24 Elapsed\n","\tSteps Per Second: Env=1259, Inference=159\n","\tTrain=435\n","\n","Allocated during training - Pytorch: 0.07 GB, System: 0.24 GB\n","INFO:root:Saving policy to /content/drive/MyDrive/nmmo/runs/nmmo_20231024_184251/policy_store/nmmo_20231024_184251.000001\n","INFO:root:PolicyPool: Updated policies: dict_keys(['learner'])\n","Allocated during evaluation - Pytorch: 0.00 GB, System: 0.00 GB\n","Epoch: 1 - 2K steps - 0:01:29 Elapsed\n","\tSteps Per Second: Env=632, Inference=4035\n","\tTrain=617\n","\n","Allocated during training - Pytorch: 0.01 GB, System: 0.00 GB\n","INFO:root:PolicyPool: Updated policies: dict_keys(['learner'])\n","Allocated during evaluation - Pytorch: 0.00 GB, System: 0.00 GB\n","Epoch: 2 - 3K steps - 0:01:33 Elapsed\n","\tSteps Per Second: Env=580, Inference=3956\n","\tTrain=578\n","\n","Allocated during training - Pytorch: 0.01 GB, System: 0.00 GB\n","INFO:root:PolicyPool: Updated policies: dict_keys(['learner'])\n","Allocated during evaluation - Pytorch: 0.00 GB, System: 0.00 GB\n","Epoch: 3 - 4K steps - 0:01:38 Elapsed\n","\tSteps Per Second: Env=440, Inference=3858\n","\tTrain=712\n","\n","Allocated during training - Pytorch: 0.01 GB, System: 0.00 GB\n","INFO:root:Saving policy to /content/drive/MyDrive/nmmo/runs/nmmo_20231024_184251/policy_store/nmmo_20231024_184251.000004\n"]}],"source":["# If everything is correctly installed, this should run\n","\n","!python train.py --runs-dir $CKPT_DIR --local-mode true --train-num-steps=5_000"]},{"cell_type":"markdown","metadata":{"id":"knSBz67PCYbM"},"source":["# Manually create your custom curriculum\n","\n","1. Use pre-built evaluation functions and TaskSpec to define training tasks.\n","2. Define your own evaluation functions.\n","3. Check if your training task tasks are valid and pickable. Must satisfy both.\n","4. Generate the task embedding file using the task encoder.\n","5. Train agents using the task embedding file.\n","6. Extract the training task stats."]},{"cell_type":"markdown","metadata":{"id":"xtRxRe5LFGq8"},"source":["## Define simple training tasks using pre-built functions\n","\n","For the full list of pre-built functions, see https://github.com/NeuralMMO/environment/blob/2.0/nmmo/task/base_predicates.py"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3H2qL-GbC9Id"},"outputs":[],"source":["curriculum = []\n","# Training tasks for nmmo are defined using TaskSpec class\n","from nmmo.task.task_spec import TaskSpec\n","\n","# Let's start with pre-built eval functions\n","from nmmo.task.base_predicates import CountEvent, InventorySpaceGE, TickGE, norm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":143,"status":"ok","timestamp":1698174324971,"user":{"displayName":"Kyoung Choe","userId":"14938553623215115470"},"user_tz":420},"id":"QZrJsvK7DUz3","outputId":"09c78f3d-35eb-4b37-ca7e-8d67f5ca39f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Curriculum so far:\n"," [TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'GO_FARTHEST', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'EAT_FOOD', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'DRINK_WATER', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'SCORE_HIT', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'HARVEST_ITEM', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'LEVEL_UP', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'GO_FARTHEST', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'EAT_FOOD', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'DRINK_WATER', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'SCORE_HIT', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'HARVEST_ITEM', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'LEVEL_UP', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'GO_FARTHEST', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'EAT_FOOD', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'DRINK_WATER', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'SCORE_HIT', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'HARVEST_ITEM', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None), TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'LEVEL_UP', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None)]\n","\n","One example training task:\n"," TaskSpec(eval_fn=<function CountEvent at 0x7eeb3b125120>, eval_fn_kwargs={'event': 'GO_FARTHEST', 'N': 10}, task_cls=<class 'nmmo.task.task_api.Task'>, task_kwargs={}, reward_to='agent', sampling_weight=1.0, embedding=None, predicate=None)\n"]}],"source":["# Here are very simple training tasks, based on a pre-built function, CountEvent\n","\n","# Agents have completed the task if they have done the event N times\n","essential_events = [\n","    \"GO_FARTHEST\",\n","    \"EAT_FOOD\",\n","    \"DRINK_WATER\",\n","    \"SCORE_HIT\",\n","    \"HARVEST_ITEM\",\n","    \"LEVEL_UP\",\n","]\n","\n","for event_code in essential_events:\n","    curriculum.append(\n","        TaskSpec(\n","            eval_fn=CountEvent,  # is a pre-built eval function\n","            eval_fn_kwargs={\"event\": event_code, \"N\": 10},  # kwargs for CountEvent\n","        )\n","    )\n","\n","print(\"Curriculum so far:\\n\", curriculum)\n","print(\"\\nOne example training task:\\n\", curriculum[0])"]},{"cell_type":"markdown","metadata":{"id":"yk_F9svVFVhw"},"source":["## Define custom training tasks\n","\n","You can also use the attributes available via GameState (gs) and subject. For example usage, please refer to the pre-built functions: https://github.com/NeuralMMO/environment/blob/2.0/nmmo/task/base_predicates.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a0M0I7DvEgRQ"},"outputs":[],"source":["# You can also use pre-built eval functions to define your own function\n","def PracticeInventoryManagement(gs, subject, space, num_tick):\n","    return norm(InventorySpaceGE(gs, subject, space) * TickGE(gs, subject, num_tick))\n","\n","# Training tasks are defined using TaskSpec\n","for space in [2, 4, 8]:\n","    curriculum.append(\n","        TaskSpec(\n","            eval_fn=PracticeInventoryManagement,\n","            eval_fn_kwargs={\"space\": space, \"num_tick\": 500},\n","        )\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"urTuLXSgF2dS"},"outputs":[],"source":["# The eval functions can be built directly from accessing attributes in GameState and subject\n","# GameState: https://github.com/NeuralMMO/environment/blob/2.0/nmmo/task/game_state.py#L32\n","\n","def PracticeEating(gs, subject):\n","    \"\"\"The progress, the max of which is 1, should\n","    * increase small for each eating\n","    * increase big for the 1st and 3rd eating\n","    * reach 1 with 10 eatings\n","    \"\"\"\n","    num_eat = len(subject.event.EAT_FOOD)\n","    progress = num_eat * 0.06\n","    if num_eat >= 1:\n","        progress += 0.1\n","    if num_eat >= 3:\n","        progress += 0.3\n","    return norm(progress)  # norm is a helper function to normalize the value to [0, 1]\n","\n","curriculum.append(TaskSpec(eval_fn=PracticeEating, eval_fn_kwargs={}))"]},{"cell_type":"markdown","metadata":{"id":"RvtkTSl5G1pm"},"source":["## Check if your training task tasks are valid and pickable\n","\n","So that these can be used for training.\n","\n","Save your curriculum into a separate python file, so that it can be imported. In this tutorial, the above curriculum has been saved to `curriculum_tutorial.py`, and we are using it."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1176,"status":"ok","timestamp":1698189043224,"user":{"displayName":"Kyoung Choe","userId":"14938553623215115470"},"user_tz":420},"id":"25bOmSrWGtj3","outputId":"be7c1fef-6f92-40b4-d4ca-17a0232bb833"},"outputs":[{"name":"stdout","output_type":"stream","text":["The number of training tasks in the curriculum: 10\n"]}],"source":["# Import the custom curriculum\n","import curriculum_generation.curriculum_tutorial as tutorial\n","CURRICULUM = tutorial.curriculum\n","print(\"The number of training tasks in the curriculum:\", len(CURRICULUM))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5217,"status":"ok","timestamp":1698177826694,"user":{"displayName":"Kyoung Choe","userId":"14938553623215115470"},"user_tz":420},"id":"zqYRSTA2He89","outputId":"3400d3d5-92a7-4c44-a1d8-04670512e1f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["All training tasks are valid.\n"]}],"source":["# Check if these task specs are valid in the nmmo environment\n","# Invalid tasks will crash your agent training\n","from nmmo.task.task_spec import check_task_spec\n","\n","results = check_task_spec(CURRICULUM)\n","num_error = 0\n","for result in results:\n","  if result[\"runnable\"] is False:\n","    print(\"ERROR: \", result[\"spec_name\"])\n","    num_error += 1\n","assert num_error == 0, \"Invalid task specs will crash training. Please fix them.\"\n","print(\"All training tasks are valid.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":387,"status":"ok","timestamp":1698177828887,"user":{"displayName":"Kyoung Choe","userId":"14938553623215115470"},"user_tz":420},"id":"La7umC0fK4tc","outputId":"76d66cc5-0901-4a99-ad26-f8da77f63b74"},"outputs":[{"name":"stdout","output_type":"stream","text":["All training tasks are picklable.\n"]}],"source":["# The task_spec must be picklable to be used for agent training\n","CURRICULUM_FILE_PATH = \"custom_curriculum_with_embedding.pkl\"\n","with open(CURRICULUM_FILE_PATH, \"wb\") as f:\n","  import dill\n","  dill.dump(CURRICULUM, f)\n","print(\"All training tasks are picklable.\")"]},{"cell_type":"markdown","metadata":{"id":"Q6fp1rJPMXkD"},"source":["## Generate the task embedding file\n","\n","To use the curriculum for agent training, the curriculum, task_spec, should be saved to a file with the embeddings using the task encoder. The task encoder uses a coding LLM to encode the task_spec into a vector."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":322,"status":"ok","timestamp":1698191352086,"user":{"displayName":"Kyoung Choe","userId":"14938553623215115470"},"user_tz":420},"id":"9cT463xYMRYT","outputId":"f6d866c6-f614-43b0-aed6-6c92693669ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/nmmo\n","/content/drive/MyDrive/nmmo/baselines\n"]}],"source":["%cd $WORK_DIR\n","%cd baselines\n","\n","import curriculum_generation\n","from curriculum_generation.task_encoder import TaskEncoder\n","\n","# The codegen25 7b model is the default, but it does not work with the free colab tier\n","LLM_CHECKPOINT = \"Salesforce/codegen25-7b-instruct\"\n","CURRICULUM_FILE_PATH = \"custom_curriculum_with_embedding.pkl\""]},{"cell_type":"markdown","metadata":{"id":"Uu182I4BNlI8"},"source":["<font color=red size=5>**NOTE: It takes ~20 minutes to download the 7B model, and it does NOT work in the free tier due to insufficient RAM while loading.**</font>\n","\n","If you have enough storage in your google drive, you can save these pre-trained models to your drive and re-use them later. Please see https://stackoverflow.com/questions/73842234/setting-huggingface-cache-in-google-colab-notebook-to-google-drive"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["1071179afaf04745ba77aacca1890df2","1f7e0ccb5cc349c39966e8129e85d44a","b7fc023ed2fc43239890f3617a0661ef","3692ecae368d45cf965251f97ff4303f","ef301bfe108d46a1ac8eb8d4e2866051","b3f7e92082094283aa980d37f4de2e59","d1c755a6e47446e2be4c0c814eab3daa","70fa941e167d459aaf069701ed7d0ee8","fc661e5a8693412c9d8302f34d4f80b8","69134520cd8f4a7bb8ddfa27c868a5d7","55f962e9d51c44e8aadd4f495213fff3"]},"executionInfo":{"elapsed":146737,"status":"ok","timestamp":1698191502033,"user":{"displayName":"Kyoung Choe","userId":"14938553623215115470"},"user_tz":420},"id":"DR3vhXGyMtxs","outputId":"ea71c353-5e37-4e15-8760-67b34c057173"},"outputs":[{"name":"stderr","output_type":"stream","text":["Using unk_token, but it is not set yet.\n","Using unk_token, but it is not set yet.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1071179afaf04745ba77aacca1890df2","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  3.07it/s]\n","100%|██████████| 5/5 [00:02<00:00,  2.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Generating the task embedding done.\n"]}],"source":["# Check the available RAM before running below\n","import psutil\n","avail_ram = psutil.virtual_memory()[1]/1_000_000_000  # GB\n","assert avail_ram > 16, \"Need a high-ram instance, available with Colab Pro.\"\n","\n","# Get the task embeddings for the training tasks and save to file\n","# You need to provide the curriculum file as a module to the task encoder\n","with TaskEncoder(LLM_CHECKPOINT, curriculum_generation.curriculum_tutorial) as task_encoder:\n","    task_encoder.get_task_embedding(CURRICULUM, save_to_file=CURRICULUM_FILE_PATH)\n","\n","print(\"Generated the task embedding file.\")"]},{"cell_type":"markdown","metadata":{"id":"1Wc33tKoSw5z"},"source":["## Train agents with your curriculum\n","\n","Provide your curriculum file with the arg `--tasks-path` like below."]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":170005,"status":"ok","timestamp":1698191739620,"user":{"displayName":"Kyoung Choe","userId":"14938553623215115470"},"user_tz":420},"id":"tHK0NsEYSfB1","outputId":"8cd299a6-85f2-4e46-ab2a-2589d041ce93"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO:root:Training run: nmmo_20231024_235253 (/content/drive/MyDrive/nmmo/runs/nmmo_20231024_235253)\n","INFO:root:Training args: Namespace(attend_task='none', attentional_decode=True, bptt_horizon=8, checkpoint_interval=30, clip_coef=0.1, death_fog_tick=None, device='cuda', early_stop_agent_num=8, encode_task=True, eval_batch_size=32768, eval_mode=False, eval_num_policies=2, eval_num_rounds=1, eval_num_steps=1000000, explore_bonus_weight=0.01, extra_encoders=True, heal_bonus_weight=0.03, hidden_size=256, input_size=256, learner_weight=1.0, local_mode=False, map_size=128, maps_path='maps/train/', max_episode_length=1024, max_opponent_policies=0, meander_bonus_weight=0.02, num_agents=128, num_buffers=2, num_cores=None, num_envs=6, num_lstm_layers=0, num_maps=128, num_npcs=256, policy_store_dir=None, ppo_learning_rate=0.00015, ppo_training_batch_size=128, ppo_update_epochs=3, resilient_population=0.2, rollout_batch_size=32768, run_name='nmmo_20231024_235253', runs_dir='/content/drive/MyDrive/nmmo/runs', seed=1, spawn_immunity=20, sqrt_achievement_rewards=False, task_size=4096, tasks_path='reinforcement_learning/curriculum_with_embedding.pkl', track='rl', train_num_steps=10000000, use_serial_vecenv=False, wandb_entity=None, wandb_project=None)\n","INFO:root:Using policy store from /content/drive/MyDrive/nmmo/runs/nmmo_20231024_235253/policy_store\n","Allocated 93.70 MB to environments. Only accurate for Serial backend.\n","PolicyPool sample_weights: [128]\n","Allocated to storage - Pytorch: 0.00 GB, System: 3.41 GB\n","INFO:root:PolicyPool: Updated policies: dict_keys(['learner'])\n","Allocated during evaluation - Pytorch: 0.01 GB, System: 0.76 GB\n","Epoch: 0 - 32K steps - 0:00:38 Elapsed\n","\tSteps Per Second: Env=1905, Inference=5271\n","\tTrain=756\n","\n","Allocated during training - Pytorch: 0.07 GB, System: 3.61 GB\n","INFO:root:Saving policy to /content/drive/MyDrive/nmmo/runs/nmmo_20231024_235253/policy_store/nmmo_20231024_235253.000001\n","INFO:root:PolicyPool: Updated policies: dict_keys(['learner'])\n","Allocated during evaluation - Pytorch: 0.00 GB, System: 0.04 GB\n","Epoch: 1 - 65K steps - 0:02:23 Elapsed\n","\tSteps Per Second: Env=847, Inference=7591\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/pufferlib/utils.py\", line 223, in wrapper\n","    result = func(*args, **kwargs)\n","  File \"/content/drive/MyDrive/nmmo/baselines/reinforcement_learning/clean_pufferl.py\", line 620, in train\n","    self.optimizer.step()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 373, in wrapper\n","    out = func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n","    ret = func(self, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 163, in step\n","    adam(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 311, in adam\n","    func(params,\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 552, in _multi_tensor_adam\n","    bias_correction2 = [1 - beta2 ** _get_value(step) for step in device_state_steps]\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\", line 552, in <listcomp>\n","    bias_correction2 = [1 - beta2 ** _get_value(step) for step in device_state_steps]\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 84, in _get_value\n","    def _get_value(x):\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/nmmo/baselines/train.py\", line 135, in <module>\n","    reinforcement_learning_track(trainer, args)\n","  File \"/content/drive/MyDrive/nmmo/baselines/train.py\", line 68, in reinforcement_learning_track\n","    trainer.train(\n","  File \"/usr/local/lib/python3.10/dist-packages/pufferlib/utils.py\", line 223, in wrapper\n","    result = func(*args, **kwargs)\n","KeyboardInterrupt\n","Process Process-12:\n","Process Process-9:\n","Process Process-10:\n","Process Process-8:\n","Process Process-7:\n","Process Process-5:\n","Exception ignored in atexit callback: <function _exit_function at 0x7989b0c63c70>\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 357, in _exit_function\n","Process Process-4:\n","Process Process-2:\n","Process Process-11:\n","Process Process-3:\n","Process Process-6:\n","Process Process-1:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pufferlib/vectorization.py\", line 349, in _worker_process\n","    request, args, kwargs = request_queue.get()\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n","    res = self._recv_bytes()\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pufferlib/vectorization.py\", line 349, in _worker_process\n","    request, args, kwargs = request_queue.get()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n","    res = self._recv_bytes()\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 317, in _bootstrap\n","    util._exit_function()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 360, in _exit_function\n","    _run_finalizers()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/local/lib/python3.10/dist-packages/pufferlib/vectorization.py\", line 349, in _worker_process\n","    request, args, kwargs = request_queue.get()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n","    finalizer()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n","    res = self._recv_bytes()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pufferlib/vectorization.py\", line 349, in _worker_process\n","    request, args, kwargs = request_queue.get()\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/local/lib/python3.10/dist-packages/pufferlib/vectorization.py\", line 349, in _worker_process\n","    request, args, kwargs = request_queue.get()\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n","    res = self._callback(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 199, in _finalize_join\n","    thread.join()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/local/lib/python3.10/dist-packages/pufferlib/vectorization.py\", line 349, in _worker_process\n","    request, args, kwargs = request_queue.get()\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n","    res = self._recv_bytes()\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n","    res = self._recv_bytes()\n","  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n","    self._wait_for_tstate_lock()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n","    res = self._recv_bytes()\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","  File \"/usr/local/lib/python3.10/dist-packages/pufferlib/vectorization.py\", line 349, in _worker_process\n","    request, args, kwargs = request_queue.get()\n","\n","During handling of the above exception, another exception occurred:\n","\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n","    res = self._recv_bytes()\n","Traceback (most recent call last):\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n","    buf = self._recv(4)\n","\n","During handling of the above exception, another exception occurred:\n","\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 317, in _bootstrap\n","    util._exit_function()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 360, in _exit_function\n","    _run_finalizers()\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n","    finalizer()\n","\n","During handling of the above exception, another exception occurred:\n","\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n","    res = self._callback(*self._args, **self._kwargs)\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 199, in _finalize_join\n","    thread.join()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 317, in _bootstrap\n","    util._exit_function()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 317, in _bootstrap\n","    util._exit_function()\n","  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n","    self._wait_for_tstate_lock()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 360, in _exit_function\n","    _run_finalizers()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 360, in _exit_function\n","    _run_finalizers()\n","  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n","    finalizer()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n","    finalizer()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 317, in _bootstrap\n","    util._exit_function()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 317, in _bootstrap\n","    util._exit_function()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n","    res = self._callback(*self._args, **self._kwargs)\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n","    res = self._callback(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 360, in _exit_function\n","    _run_finalizers()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 360, in _exit_function\n","    _run_finalizers()\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 199, in _finalize_join\n","    thread.join()\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 199, in _finalize_join\n","    thread.join()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n","    finalizer()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n","    finalizer()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 317, in _bootstrap\n","    util._exit_function()\n","  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n","    self._wait_for_tstate_lock()\n","  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n","    self._wait_for_tstate_lock()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n","    res = self._callback(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n","    res = self._callback(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 360, in _exit_function\n","    _run_finalizers()\n","  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 199, in _finalize_join\n","    thread.join()\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 199, in _finalize_join\n","    thread.join()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n","    finalizer()\n","  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n","    self._wait_for_tstate_lock()\n","KeyboardInterrupt\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n","    self._wait_for_tstate_lock()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n","    res = self._callback(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 199, in _finalize_join\n","    thread.join()\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n","    self._wait_for_tstate_lock()\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pufferlib/vectorization.py\", line 349, in _worker_process\n","    request, args, kwargs = request_queue.get()\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n","    res = self._recv_bytes()\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 317, in _bootstrap\n","    util._exit_function()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 360, in _exit_function\n","    _run_finalizers()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n","    finalizer()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n","    res = self._callback(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 199, in _finalize_join\n","    thread.join()\n","  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n","    self._wait_for_tstate_lock()\n","  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pufferlib/vectorization.py\", line 349, in _worker_process\n","    request, args, kwargs = request_queue.get()\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n","    res = self._recv_bytes()\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 317, in _bootstrap\n","    util._exit_function()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 360, in _exit_function\n","    _run_finalizers()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n","    finalizer()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n","    res = self._callback(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 199, in _finalize_join\n","    thread.join()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n","    self._wait_for_tstate_lock()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","  File \"/usr/local/lib/python3.10/dist-packages/pufferlib/vectorization.py\", line 349, in _worker_process\n","    request, args, kwargs = request_queue.get()\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n","    res = self._recv_bytes()\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 317, in _bootstrap\n","    util._exit_function()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 360, in _exit_function\n","    _run_finalizers()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n","    finalizer()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n","    res = self._callback(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 199, in _finalize_join\n","    thread.join()\n","  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n","    self._wait_for_tstate_lock()\n","  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/pufferlib/vectorization.py\", line 349, in _worker_process\n","    request, args, kwargs = request_queue.get()\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n","    res = self._recv_bytes()\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 317, in _bootstrap\n","    util._exit_function()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 360, in _exit_function\n","    _run_finalizers()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n","    finalizer()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n","    res = self._callback(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 199, in _finalize_join\n","    thread.join()\n","  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n","    self._wait_for_tstate_lock()\n","  File \"/usr/local/lib/python3.10/dist-packages/pufferlib/vectorization.py\", line 349, in _worker_process\n","    request, args, kwargs = request_queue.get()\n","  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n","    res = self._recv_bytes()\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 317, in _bootstrap\n","    util._exit_function()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 360, in _exit_function\n","    _run_finalizers()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n","    finalizer()\n","  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n","    res = self._callback(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 199, in _finalize_join\n","    thread.join()\n","  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n","    self._wait_for_tstate_lock()\n","  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","KeyboardInterrupt\n","^C\n"]}],"source":["!python train.py --runs-dir $CKPT_DIR --tasks-path $CURRICULUM_FILE_PATH"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyO/oXtXNwtptWj06h6CyH5y","gpuType":"T4","machine_shape":"hm","mount_file_id":"1AZt_eEGTEZrnX3iJC7jHw7lbBTNaoMoj","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1071179afaf04745ba77aacca1890df2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f7e0ccb5cc349c39966e8129e85d44a","IPY_MODEL_b7fc023ed2fc43239890f3617a0661ef","IPY_MODEL_3692ecae368d45cf965251f97ff4303f"],"layout":"IPY_MODEL_ef301bfe108d46a1ac8eb8d4e2866051"}},"1f7e0ccb5cc349c39966e8129e85d44a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3f7e92082094283aa980d37f4de2e59","placeholder":"​","style":"IPY_MODEL_d1c755a6e47446e2be4c0c814eab3daa","value":"Loading checkpoint shards: 100%"}},"3692ecae368d45cf965251f97ff4303f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69134520cd8f4a7bb8ddfa27c868a5d7","placeholder":"​","style":"IPY_MODEL_55f962e9d51c44e8aadd4f495213fff3","value":" 3/3 [02:20&lt;00:00, 43.76s/it]"}},"55f962e9d51c44e8aadd4f495213fff3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69134520cd8f4a7bb8ddfa27c868a5d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70fa941e167d459aaf069701ed7d0ee8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3f7e92082094283aa980d37f4de2e59":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7fc023ed2fc43239890f3617a0661ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_70fa941e167d459aaf069701ed7d0ee8","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fc661e5a8693412c9d8302f34d4f80b8","value":3}},"d1c755a6e47446e2be4c0c814eab3daa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef301bfe108d46a1ac8eb8d4e2866051":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc661e5a8693412c9d8302f34d4f80b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
